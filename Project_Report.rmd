---
title: "Prediction Model on Human Activity"
author: "Ronit Rudra"
date: "Saturday, September 26, 2015"
output: html_document
---

## Executive Summary ##
This report aims at addressing the issue of building a highly accurate model for predicting the quality of weightlifting and exercising done by the test subjects based on biometric readings. The quality is divided into 5 classes A through E and has a lot of variables it depends on. The subsequent sections outline the methodology of analyzing the data, transforming it, building train and test sets and to build a responsive moodel to accurately draw out relationship between the input(biometric) and output(quality of exercise).
The model used was `Random Forest` and by using cross validation to reduce over-fitting, it was obsevered that the proposed model was very accurate in predicting with an error rate of just `0.45%`.

## 1. Reading in Data ###

Assuming that the required dataset is in the `current working directory`, the following steps are performed:

```{r,echo=TRUE,message=FALSE,warning=FALSE,cache=TRUE}
# Load required packages
library(caret) # also loads lattice and ggplot2
# the datasets contain aretfacts such as NA, #DIv/0!,empty etc which are to be replaced with NA
train <- read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!",""),stringsAsFactors=FALSE)
test<-read.csv("pml-testing.csv",na.strings=c("NA","#DIV/0!",""),stringsAsFactors=FALSE)
train$user_name <- as.factor(train$user_name)
train$classe <- as.factor(train$classe)
#str(train)        # Uncomment to see structure. Commented to reduce report size
```
<ul>
<li> The "classe" variable is the outcome while others can be used as predictors </li>
<li> The "X" variable is the row number and should be omitted from the dataset </li>
<li> The "user_name" variable is also converted to factors for ease of classification </li>
</ul>

## 2. Data Transforms and Covariate Generation ## 

1. To account for overfitting it is appropriate to split the training datset into multiple cross validation sets.
In the further subheading, this step is performed during the model training itself.

```{r, echo=TRUE,message=FALSE,cache=TRUE}
set.seed(1000)
splits <- createDataPartition(train$classe,p=0.65,list=FALSE)
train_train <- train[splits,-1]            # Train subset
train_test <- train[-splits,-1]            # Test subset
```

2. We also need to check the covariates (predictors) for zero variance. Covariates having zero or close to zero variance play no role in model generation and end up biasing the data. Hence, the next code chunk checks the covariates for zero variance and then removes them. This is the Level 1 near zero variance test and a second one will be performed furhter ahead.

```{r, echo=TRUE,message=FALSE}
l<-nearZeroVar(train,saveMetrics = F)
train <- train[,-l]
```

3. Some variables contain a lot of NA values and are unnecessary for behaving as covariates.

```{r,echo=TRUE,cache=TRUE}
keep <- NULL
for(i in 1:length(train)){
    if(sum(is.na(train[,i]))/nrow(train)<0.10){
        keep <- c(keep,i)}
}
# Select Necessary Columns
train <- train[,keep]
```
 In the above code block, any variables with more than 10% NA values are removed from the dataset
 
4. The variables in columns 1,3,4,5,6 namely `X`, `raw_timestamp_part_1`, `raw_timestamp_part_2`, `cvtd_timestamp`, `new_window` and `num_window` are not required and can be reomved.

```{r,echo=TRUE,cache=TRUE}
train <- train[,-c(1,3,4,5,6)]
```

5. A second near zero variance test is performed
```{r,echo=TRUE,cache=TRUE}
nearZeroVar(train,saveMetrics = T)
```

The result shows that all the covariates are suitable for inclusion in the prediction model as they set the flag to `FALSE` for zero and near zero variances.

6. Plotting Predictors
```{r,echo=TRUE,cache=TRUE,message=FALSE,warning=FALSE}
# 1st 5 predictors vs outcome
featurePlot(train[,1:5],train[,54],plot="pairs")
# next 5 predictors vs outcome
featurePlot(train[,6:10],train[,54],plot="pairs")
# Predictors 20 through 25
featurePlot(train[,20:25],train[,54],plot="pairs")
```

*No feature plots are used to reduce the size of the report*

## 3. Prediction model and Results ##
`Random Forest` was chosen to be the suitable model for classification considering:
    + Very High Accuracy
    + Multiclass output
    + Large number of Covariates
    + Overfitting can be reduced by using cross-validation
    
```{r,echo=TRUE,warning=FALSE,cache=TRUE}
# create model with 5 fold cross validation
model <- train(classe~.,data=train,method="rf",trControl=trainControl(method="cv",number=5))
# display model and confusion matrix
model$finalModel
# check model predictions
train_test <- train[-splits,]
pred <- predict(model, train_test)
train_test$predRight <- pred==train_test$classe
# confusion matrix
table(pred,train_test$classe)
```
A random part of the training dataset was used for the prediction and the confusion matrix shows 100% classification. It could mean that the model is highly accurate or has over-fitted to the data.

**Furthermore, the tesing dataset with 20 instances was used to test the accuracy and acheived a 100% prediction rate as observed in the submission part of this assignment.**

## 4. Conclusion ##
The results conclude that Random Forest shows a high degree of accuracy when used for such classification purposes. The error rate is **0.45%** which is very low and within experimental limits. The confusion matrix of the 5 classes denote a negligible amount of misclassification.
